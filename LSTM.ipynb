{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries \n",
    "\n",
    "import numpy as np \n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from keras.layers import LSTM, Input, Dropout, Dense, RepeatVector, TimeDistributed\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import random \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, RepeatVector, TimeDistributed, Dense\n",
    "import seaborn as sns \n",
    "import time\n",
    "#import plotly.graph_objs as go\n",
    "#from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set random seed \n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load the dataset\n",
    "data1 = pd.read_csv('Nano07.csv')\n",
    "dataframe = data1\n",
    "\n",
    "# Convert 'timestamp' column to datetime\n",
    "dataframe['timestamp'] = pd.to_datetime(dataframe['timestamp'])\n",
    "\n",
    "# Filter relevant columns\n",
    "df = dataframe[['timestamp', 'jetson_vdd_cpu_gpu_cv_mw', 'jetson_gpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_vdd_in_mw', 'jetson_cpu_usage_percent',\n",
    "                'jetson_ram_usage_mb', 'node_network_receive_bytes_total_KBps', 'node_network_transmit_bytes_total_KBps']]\n",
    "df.set_index('timestamp', inplace=True)\n",
    "# Replace zero values with 0.01\n",
    "df.replace(0, 0.01, inplace=True)\n",
    "\n",
    "# Count the number of rows where zero values were replaced with 0.01\n",
    "num_rows_with_zero_replaced = len(df[(df == 0.01).any(axis=1)])\n",
    "print(f\"Number of rows where zero values were replaced: {num_rows_with_zero_replaced}\")\n",
    "\n",
    "# check if there are any remaining zero values\n",
    "remaining_zeros = df[(df == 0).any(axis=1)]\n",
    "print(f\"Remaining rows with zero values: {len(remaining_zeros)}\")\n",
    "# Print start and end date\n",
    "print(\"Start date is:\", df.index.min())\n",
    "print(\"End date is:\", df.index.max())\n",
    "\n",
    "# Create the line plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x=df.index, y='jetson_vdd_cpu_gpu_cv_mw', data=df, label='GPU/CPU Power')\n",
    "sns.lineplot(x=df.index, y='jetson_gpu_usage_percent', data=df, label='GPU Usage in %')\n",
    "sns.lineplot(x=df.index, y='jetson_board_temperature_celsius', data=df, label='Device Temperature')\n",
    "sns.lineplot(x=df.index, y='jetson_vdd_in_mw', data=df, label='Total Power')\n",
    "sns.lineplot(x=df.index, y='jetson_cpu_usage_percent', data=df, label='CPU Usage %')\n",
    "sns.lineplot(x=df.index, y='jetson_ram_usage_mb', data=df, label='RAM Usage')\n",
    "sns.lineplot(x=df.index, y='node_network_receive_bytes_total_KBps', data=df, label='Network Received')\n",
    "sns.lineplot(x=df.index, y='node_network_transmit_bytes_total_KBps', data=df, label='Network Transmit')\n",
    "plt.title('Jetson Device Metrics Over Time')\n",
    "plt.ylabel('Usage')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.xticks(rotation=45)\n",
    "plt.gcf().set_facecolor('white')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7601fcf9722105ce"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Train and Test Split \n",
    "split_index = int(len(df) * 0.8)\n",
    "train = df.iloc[:split_index]\n",
    "test = df.iloc[split_index:]\n",
    "\n",
    "# Print the start and end dates for each split\n",
    "print(\"Train start date:\", train.index.min())\n",
    "print(\"Train end date:\", train.index.max())\n",
    "print(\"Test start date:\", test.index.min())\n",
    "print(\"Test end date:\", test.index.max())\n",
    "print(\"Train set shape:\", train.shape)\n",
    "print(\"Test set shape:\", test.shape)\n",
    "\n",
    "# Create a line plot for both train and test data\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the split\n",
    "sns.lineplot(x=train.index, y=train['jetson_vdd_cpu_gpu_cv_mw'], label='Train GPU/CPU Power')\n",
    "sns.lineplot(x=test.index, y=test['jetson_vdd_cpu_gpu_cv_mw'], label='Test GPU/CPU Power')\n",
    "\n",
    "sns.lineplot(x=train.index, y=train['jetson_gpu_usage_percent'], label='Train GPU Usage in %')\n",
    "sns.lineplot(x=test.index, y=test['jetson_gpu_usage_percent'], label='Test GPU Usage in %')\n",
    "\n",
    "sns.lineplot(x=train.index, y=train['jetson_board_temperature_celsius'], label='Train Device Temperature')\n",
    "sns.lineplot(x=test.index, y=test['jetson_board_temperature_celsius'], label='Test Device Temperature')\n",
    "\n",
    "sns.lineplot(x=train.index, y=train['jetson_vdd_in_mw'], label='Train Total Power')\n",
    "sns.lineplot(x=test.index, y=test['jetson_vdd_in_mw'], label='Test Total Power')\n",
    "\n",
    "sns.lineplot(x=train.index, y=train['jetson_cpu_usage_percent'], label='Train CPU Usage %')\n",
    "sns.lineplot(x=test.index, y=test['jetson_cpu_usage_percent'], label='Test CPU Usage %')\n",
    "\n",
    "sns.lineplot(x=train.index, y=train['jetson_ram_usage_mb'], label='Train RAM Usage')\n",
    "sns.lineplot(x=test.index, y=test['jetson_ram_usage_mb'], label='Test RAM Usage')\n",
    "\n",
    "sns.lineplot(x=train.index, y=train['node_network_receive_bytes_total_KBps'], label='Train Network Received')\n",
    "sns.lineplot(x=test.index, y=test['node_network_receive_bytes_total_KBps'], label='Test Network Received')\n",
    "\n",
    "sns.lineplot(x=train.index, y=train['node_network_transmit_bytes_total_KBps'], label='Train Network Transmit')\n",
    "sns.lineplot(x=test.index, y=test['node_network_transmit_bytes_total_KBps'], label='Test Network Transmit')\n",
    "\n",
    "plt.title('Train and Test Data for CPU and RAM Usage')\n",
    "plt.ylabel('Usage')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"train data\", train.head())\n",
    "print(\"test data\", test.head())\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd81da714542fff4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "seq_size = 40 # Number of time steps to look back \n",
    "# larger sequence size (look further back) may improve forecasting \n",
    "\n",
    "def to_sequence(x, y, seq_size=1):\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    \n",
    "    for i in range(len(x)-seq_size):\n",
    "        x_values.append(x.iloc[i:(i+seq_size)].values)\n",
    "        y_values.append(y.iloc[i:(i+seq_size)].values)  # Adjust this line for correct target shape\n",
    "        \n",
    "    return np.array(x_values), np.array(y_values)\n",
    "\n",
    "\n",
    "trainX, trainY = to_sequence(\n",
    "    train[['jetson_vdd_cpu_gpu_cv_mw', 'jetson_vdd_cpu_gpu_cv_mw', 'jetson_board_temperature_celsius', 'jetson_vdd_in_mw', 'jetson_cpu_usage_percent', 'jetson_ram_usage_mb', \n",
    "           'node_network_receive_bytes_total_KBps', 'node_network_transmit_bytes_total_KBps']], \n",
    "    train[['jetson_vdd_cpu_gpu_cv_mw', 'jetson_vdd_cpu_gpu_cv_mw', 'jetson_board_temperature_celsius', 'jetson_vdd_in_mw', 'jetson_cpu_usage_percent', 'jetson_ram_usage_mb', \n",
    "           'node_network_receive_bytes_total_KBps', 'node_network_transmit_bytes_total_KBps']], \n",
    "    seq_size\n",
    ")\n",
    "\n",
    "testX, testY = to_sequence(\n",
    "    test[['jetson_vdd_cpu_gpu_cv_mw', 'jetson_vdd_cpu_gpu_cv_mw', 'jetson_board_temperature_celsius', 'jetson_vdd_in_mw', 'jetson_cpu_usage_percent', 'jetson_ram_usage_mb', \n",
    "           'node_network_receive_bytes_total_KBps', 'node_network_transmit_bytes_total_KBps']], \n",
    "    test[['jetson_vdd_cpu_gpu_cv_mw', 'jetson_vdd_cpu_gpu_cv_mw', 'jetson_board_temperature_celsius', 'jetson_vdd_in_mw', 'jetson_cpu_usage_percent', 'jetson_ram_usage_mb', \n",
    "           'node_network_receive_bytes_total_KBps', 'node_network_transmit_bytes_total_KBps']], \n",
    "    seq_size\n",
    ")\n",
    "\n",
    "\n",
    "print(\"train X shape\", trainX.shape)\n",
    "print(\"train Y shape\", trainY.shape)\n",
    "print(\"test X shape\", testX.shape)\n",
    "print(\"test Y shape\", testY.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "282d4890fb5e4fe1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='tanh', recurrent_activation='sigmoid', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(64, activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
    "model.add(LSTM(32, activation='tanh', recurrent_activation='sigmoid', return_sequences=False))\n",
    "model.add(RepeatVector(trainX.shape[1]))\n",
    "model.add(LSTM(32, activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
    "model.add(LSTM(64, activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
    "model.add(LSTM(128, activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(trainX.shape[2])))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mae', metrics=[\"mape\"])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "def2c24254f8c74b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Measure the time\n",
    "start_training_time = time.time()\n",
    "# Fit the model\n",
    "history = model.fit(trainX, trainY, epochs=50, batch_size=128, validation_split=0.2, verbose=1)\n",
    "end_training_time = time.time()\n",
    "training_time = end_training_time - start_training_time\n",
    "print(f\"Total training time: {training_time:.2f} seconds\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "607c86ffaa437eb1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# training history\n",
    "training_loss = history.history['loss']\n",
    "training_mape = history.history['mape']\n",
    "val_loss = history.history['val_loss']\n",
    "val_mape = history.history['val_mape']\n",
    "epochs = range(1, len(training_loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot training and validation loss \n",
    "# plt.plot(epochs, training_loss, color='blue', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, color='green', label='Validation loss')\n",
    "\n",
    "# Plot training and validation MAPE \n",
    "plt.plot(epochs, training_mape, color='orange', label='Training MAPE')\n",
    "plt.plot(epochs, val_mape, color='red', label='Validation MAPE')\n",
    "\n",
    "plt.title('Training and Validation Loss / MAPE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss / MAPE')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Extract the final loss and MAPE values\n",
    "final_training_loss = training_loss[-1]\n",
    "final_val_loss = val_loss[-1]\n",
    "final_training_mape = training_mape[-1]\n",
    "final_val_mape = val_mape[-1]\n",
    "\n",
    "# Print the final loss and MAPE values\n",
    "print(\"Final Training Loss:\", final_training_loss)\n",
    "print(\"Final Validation Loss:\", final_val_loss)\n",
    "print(\"Final Training MAPE:\", final_training_mape)\n",
    "print(\"Final Validation MAPE:\", final_val_mape)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5d9fa2b1958e405"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# When reconstruction error (MAPE) is larger than the threshold which we set then there is anomaly\n",
    "\n",
    "# Calculate MAE for training prediction\n",
    "trainPredict = model.predict(trainX)\n",
    "trainMAE = np.mean(np.abs(trainPredict - trainX), axis=1)\n",
    "# Print the mean of test MAE\n",
    "print(\"Mean of Train MAE:\", np.mean(trainMAE))\n",
    "\n",
    "# Calculate MAPE for each sample\n",
    "trainActual = trainX  \n",
    "trainMAPE = np.mean(np.abs(trainPredict - trainActual) / trainActual, axis=1) * 100\n",
    "# trainMAPE = trainMAPE.flatten()\n",
    "\n",
    "# Print the mean of MAPE\n",
    "print(\"Mean of Train MAPE:\", np.mean(trainMAPE))\n",
    "\n",
    "print(trainMAE.shape)\n",
    "print(trainMAPE.shape)\n",
    "\n",
    "# List of feature names from the dataframe\n",
    "feature_names = [\n",
    "    'jetson_vdd_cpu_gpu_cv_mw',\n",
    "    'jetson_gpu_usage_percent',\n",
    "    'jetson_board_temperature_celsius',\n",
    "    'jetson_vdd_in_mw',\n",
    "    'jetson_cpu_usage_percent',\n",
    "    'jetson_ram_usage_mb',\n",
    "    'node_network_receive_bytes_total_KBps',\n",
    "    'node_network_transmit_bytes_total_KBps'\n",
    "]\n",
    "\n",
    "# Individual histograms for MAPE with feature names\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(trainMAPE.shape[1]):\n",
    "    plt.subplot(4, 2, i + 1)  # Create a grid layout (4 rows, 2 columns)\n",
    "    plt.hist(trainMAPE[:, i], bins=30, alpha=0.7, color='green')\n",
    "    plt.title(f'MAPE for {feature_names[i]}')\n",
    "    plt.xlabel('Mean Absolute Percentage Error (MAPE)')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# a. standard deviation method\n",
    "# thresholds = []\n",
    "# k = 3  # Define the multiplier (e.g., 3 for a 99.7% confidence interval)\n",
    "# for i in range(trainMAPE.shape[1]):\n",
    "#     feature_mean = np.mean(trainMAPE[:, i])\n",
    "#     feature_std = np.std(trainMAPE[:, i])\n",
    "#     threshold = feature_mean + k * feature_std\n",
    "#     thresholds.append(threshold)\n",
    "#     print(f\"Feature: {feature_names[i]}, Mean: {feature_mean:.2f}, Std: {feature_std:.2f}, Threshold: {threshold:.2f}\")\n",
    "\n",
    "# b. Percentile Method\n",
    "thresholds = []\n",
    "percentile = 95  # Set the desired percentile (e.g., 95th)\n",
    "for i in range(trainMAPE.shape[1]):\n",
    "    threshold = np.percentile(trainMAPE[:, i], percentile)\n",
    "    thresholds.append(threshold)\n",
    "    print(f\"Feature: {feature_names[i]}, Threshold ({percentile} Percentile): {threshold:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a4948b07cd03ff"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the number of rows and columns for the subplot grid\n",
    "num_features = trainMAPE.shape[1]\n",
    "rows = (num_features + 3) // 4  # 4 histograms per row\n",
    "\n",
    "# Create individual histograms for each feature's MAPE\n",
    "plt.figure(figsize=(16, rows * 4))\n",
    "for i in range(num_features):\n",
    "    plt.subplot(rows, 4, i + 1)\n",
    "    sns.histplot(trainMAPE[:, i], kde=True, bins=30, color='blue')\n",
    "    plt.title(f'MAPE for {feature_names[i]}')\n",
    "    plt.xlabel('MAPE')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle('Distribution of MAPE for Each Feature', fontsize=16, y=1.02)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9119995ca040544"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate reconstruction loss (MAE) for testing dataset\n",
    "testPredict = model.predict(testX)\n",
    "testMAE = np.mean(np.abs(testPredict - testX), axis=1)\n",
    "\n",
    "# Print the mean of test MAE\n",
    "print(\"Mean of Test MAE:\", np.mean(testMAE))\n",
    "\n",
    "# Calculate MAPE for each sample\n",
    "testActual = testX  # Assuming trainX contains the actual values\n",
    "testMAPE = np.mean(np.abs(testPredict - testActual) / testActual, axis=1) * 100\n",
    "\n",
    "# Print the mean of MAPE\n",
    "print(\"Mean of Test MAPE:\", np.mean(testMAPE))\n",
    "\n",
    "# Individual histograms for MAPE with feature names\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(testMAPE.shape[1]):\n",
    "    plt.subplot(4, 2, i + 1)  # Create a grid layout (4 rows, 2 columns)\n",
    "    plt.hist(testMAPE[:, i], bins=30, alpha=0.7, color='green')\n",
    "    plt.title(f'MAPE for {feature_names[i]}')\n",
    "    plt.xlabel('Mean Absolute Percentage Error (MAPE)')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe3f0c8c61469a1a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Anomaly detection based on thresholds\n",
    "anomalies = []\n",
    "for i in range(testMAPE.shape[1]):\n",
    "    feature_name = feature_names[i]\n",
    "    threshold = thresholds[i]\n",
    "    \n",
    "    # Find indices where MAPE exceeds the threshold\n",
    "    feature_anomalies = testMAPE[:, i] > threshold\n",
    "    anomaly_indices = np.where(feature_anomalies)[0]  # Get the indices of anomalies\n",
    "    \n",
    "    # Store the result for later analysis\n",
    "    anomalies.append({\n",
    "        'feature': feature_name,\n",
    "        'anomalies': feature_anomalies,\n",
    "        'threshold': threshold\n",
    "    })\n",
    "    \n",
    "    # Print out the anomalies for each feature\n",
    "    print(f\"Anomalies in {feature_name}: {len(anomaly_indices)} out of {len(feature_anomalies)} samples\")\n",
    "    \n",
    "    # Plot the MAPE values with the threshold\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Plot all MAPE values in blue\n",
    "    plt.plot(range(len(testMAPE[:, i])), testMAPE[:, i], label='MAPE Values', marker='o', linestyle='-', color='blue')\n",
    "    \n",
    "    # Highlight anomalies in red\n",
    "    plt.scatter(\n",
    "        anomaly_indices,  # x-coordinates of anomalies\n",
    "        testMAPE[anomaly_indices, i],  # y-coordinates of anomalies\n",
    "        color='red', label='Anomalies', zorder=3\n",
    "    )\n",
    "    \n",
    "    # Add the threshold line\n",
    "    plt.axhline(y=threshold, color='green', linestyle='--', label=f'Threshold = {threshold}')\n",
    "    \n",
    "    # Add title, labels, legend, and grid\n",
    "    plt.title(f\"MAPE and Threshold for {feature_name}\")\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('MAPE Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e21c82b6bc867724"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Combine anomalies across all features (if any feature has an anomaly, mark it as anomalous)\n",
    "combined_anomalies = np.any(testMAPE > thresholds, axis=1)\n",
    "\n",
    "# Print the number of anomalous time steps\n",
    "print(f\"Total anomalous time steps: {sum(combined_anomalies)} out of {len(combined_anomalies)}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3091cef4060879ad"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
