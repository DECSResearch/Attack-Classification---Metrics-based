{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Import Libraries \n",
    "\n",
    "import time\n",
    "import random \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from keras.layers import LSTM, Input, Dropout, Dense, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.layers import LSTM, RepeatVector, TimeDistributed, Dense, Bidirectional\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "814c6adaa5232a5a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a3ca66d7cee44bc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set random seed \n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load the dataset\n",
    "data1 = pd.read_csv('nano07.csv')\n",
    "dataframe = data1\n",
    "\n",
    "# Convert 'timestamp' column to datetime\n",
    "dataframe['timestamp'] = pd.to_datetime(dataframe['timestamp'])\n",
    "\n",
    "# Filter relevant columns\n",
    "df = dataframe[['timestamp', 'jetson_gpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_cpu_usage_percent', 'jetson_ram_usage_mb']]\n",
    "df.set_index('timestamp', inplace=True)\n",
    "# Replace zero values with 0.01\n",
    "df.replace(0, 0.01, inplace=True)\n",
    "\n",
    "# Count the number of rows where zero values were replaced with 0.01\n",
    "num_rows_with_zero_replaced = len(df[(df == 0.01).any(axis=1)])\n",
    "print(f\"Number of rows where zero values were replaced: {num_rows_with_zero_replaced}\")\n",
    "\n",
    "# check if there are any remaining zero values\n",
    "remaining_zeros = df[(df == 0).any(axis=1)]\n",
    "print(f\"Remaining rows with zero values: {len(remaining_zeros)}\")\n",
    "\n",
    "# Keep only rows with timestamps every 5 seconds\n",
    "df = df[df.index.second % 5 == 0]\n",
    "    \n",
    "# Print start and end date\n",
    "print(\"Start date is:\", df.index.min())\n",
    "print(\"End date is:\", df.index.max())\n",
    "\n",
    "# Create the line plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "# sns.lineplot(x=df.index, y='jetson_vdd_cpu_gpu_cv_mw', data=df, label='GPU/CPU Power')\n",
    "sns.lineplot(x=df.index, y='jetson_gpu_usage_percent', data=df, label='GPU Usage in %')\n",
    "sns.lineplot(x=df.index, y='jetson_board_temperature_celsius', data=df, label='Device Temperature')\n",
    "# sns.lineplot(x=df.index, y='jetson_vdd_in_mw', data=df, label='Total Power')\n",
    "sns.lineplot(x=df.index, y='jetson_cpu_usage_percent', data=df, label='CPU Usage %')\n",
    "sns.lineplot(x=df.index, y='jetson_ram_usage_mb', data=df, label='RAM Usage')\n",
    "# sns.lineplot(x=df.index, y='node_network_receive_bytes_total_KBps', data=df, label='Network Received')\n",
    "# sns.lineplot(x=df.index, y='node_network_transmit_bytes_total_KBps', data=df, label='Network Transmit')\n",
    "plt.title('Jetson Device Metrics Over Time')\n",
    "plt.ylabel('Usage')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.xticks(rotation=45)\n",
    "plt.gcf().set_facecolor('white')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a936984173830e1f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Visualize the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "278b4ab0e8e923bc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Scaling the dataset\n",
    "df_to_scale = df[['jetson_gpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_cpu_usage_percent', 'jetson_ram_usage_mb']]\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "\n",
    "df_standard_scaled = pd.DataFrame(scaler_standard.fit_transform(df_to_scale), columns=df_to_scale.columns, index=df.index)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# sns.lineplot(x=df_standard_scaled.index, y='jetson_vdd_cpu_gpu_cv_mw', data=df_standard_scaled, label='GPU/CPU Power (Standard')\n",
    "sns.lineplot(x=df_standard_scaled.index, y='jetson_gpu_usage_percent', data=df_standard_scaled, label='GPU Usage in % (Standard)')\n",
    "sns.lineplot(x=df_standard_scaled.index, y='jetson_board_temperature_celsius', data=df_standard_scaled, label='Device Temperature (Standard)')\n",
    "# sns.lineplot(x=df_standard_scaled.index, y='jetson_vdd_in_mw', data=df_standard_scaled, label='Total Power (Standard)')\n",
    "sns.lineplot(x=df_standard_scaled.index, y='jetson_cpu_usage_percent', data=df_standard_scaled, label='CPU Usage % (Standard)')\n",
    "sns.lineplot(x=df_standard_scaled.index, y='jetson_ram_usage_mb', data=df_standard_scaled, label='RAM Usage (Standard)')\n",
    "# sns.lineplot(x=df_standard_scaled.index, y='node_network_receive_bytes_total_KBps', data=df_standard_scaled, label='Network Received (Standard)')\n",
    "# sns.lineplot(x=df_standard_scaled.index, y='node_network_transmit_bytes_total_KBps', data=df_standard_scaled, label='Network Transmit (Standard)')\n",
    "plt.title('Scaled Jetson Device Metrics Over Time (Standard Scaler)')\n",
    "plt.ylabel('Standardized Values')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.xticks(rotation=45)\n",
    "plt.gcf().set_facecolor('white')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e269e9c099da82a0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Treat the entire dataset as training data\n",
    "train = df_standard_scaled  # Use the entire dataset as training data\n",
    "\n",
    "# Print the start and end dates for the dataset\n",
    "print(\"Train start date:\", train.index.min())\n",
    "print(\"Train end date:\", train.index.max())\n",
    "print(\"Train set shape:\", train.shape)\n",
    "\n",
    "# Plot the standardized metrics\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x=train.index, y='jetson_gpu_usage_percent', data=train, label='GPU Usage in % (Standard)')\n",
    "sns.lineplot(x=train.index, y='jetson_board_temperature_celsius', data=train, label='Device Temperature (Standard)')\n",
    "sns.lineplot(x=train.index, y='jetson_cpu_usage_percent', data=train, label='CPU Usage % (Standard)')\n",
    "sns.lineplot(x=train.index, y='jetson_ram_usage_mb', data=train, label='RAM Usage (Standard)')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Scaled Jetson Device Metrics Over Time (Standard Scaler)')\n",
    "plt.ylabel('Standardized Values')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.xticks(rotation=45)\n",
    "plt.gcf().set_facecolor('white')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f194eddc3cc050e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "seq_size = 20 # Number of time steps to look back \n",
    "# larger sequence size (look further back) may improve forecasting \n",
    "\n",
    "def to_sequence(x, y, seq_size=1):\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    \n",
    "    for i in range(len(x)-seq_size):\n",
    "        #print(i)\n",
    "        x_values.append(x.iloc[i:(i+seq_size)].values)\n",
    "        y_values.append(y.iloc[i+seq_size])\n",
    "        \n",
    "    return np.array(x_values), np.array(y_values)\n",
    "\n",
    "trainX, trainY = to_sequence(train[['jetson_gpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_cpu_usage_percent', 'jetson_ram_usage_mb']], train[['jetson_gpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_cpu_usage_percent', 'jetson_ram_usage_mb']], seq_size)\n",
    "# testX, testY = to_sequence(test[['jetson_gpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_cpu_usage_percent', 'jetson_ram_usage_mb']], test[['jetson_gpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_cpu_usage_percent', 'jetson_ram_usage_mb']], seq_size)\n",
    "\n",
    "print(\"train X shape\", trainX.shape)\n",
    "print(\"train Y shape\", trainY.shape)\n",
    "# print(\"test X shape\", testX.shape)\n",
    "# print(\"test Y shape\", testY.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "198781652684b9ea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Define iRMSE function\n",
    "# def irmse(y_true, y_pred):\n",
    "#     rmse_value = K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "#     # Avoid division by zero\n",
    "#     return 1 / (rmse_value + K.epsilon())\n",
    "\n",
    "\n",
    "# Define RMSE function\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "\n",
    "# Define the model\n",
    "# LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='tanh', recurrent_activation='sigmoid', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(32, activation='tanh', recurrent_activation='sigmoid', return_sequences=False))\n",
    "model.add(RepeatVector(trainX.shape[1]))\n",
    "model.add(LSTM(32, activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
    "model.add(LSTM(64, activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(trainX.shape[2])))\n",
    "\n",
    "# # BiLSTM\n",
    "# model = Sequential()\n",
    "# model.add(Bidirectional(LSTM(64, activation='tanh', recurrent_activation='sigmoid', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True)))\n",
    "# # model.add(Bidirectional(LSTM(64, activation='tanh', recurrent_activation='sigmoid', return_sequences=True)))\n",
    "# model.add(Bidirectional(LSTM(32, activation='tanh', recurrent_activation='sigmoid', return_sequences=False)))\n",
    "# model.add(RepeatVector(trainX.shape[1]))\n",
    "# # model.add(Bidirectional(LSTM(32, activation='tanh', recurrent_activation='sigmoid', return_sequences=True)))\n",
    "# model.add(Bidirectional(LSTM(32, activation='tanh', recurrent_activation='sigmoid', return_sequences=True)))\n",
    "# model.add(Bidirectional(LSTM(64, activation='tanh', recurrent_activation='sigmoid', return_sequences=True)))\n",
    "# model.add(TimeDistributed(Dense(trainX.shape[2])))\n",
    "\n",
    "# Compile the model with RMSE as a metric\n",
    "model.compile(optimizer= Adam(learning_rate=0.0001) , loss='mse', metrics=[rmse])\n",
    "\n",
    "# # Compile the model with RMSE and iRMSE as metrics\n",
    "# model.compile(optimizer='adam', loss='mse', metrics=[rmse, irmse])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_rmse',   \n",
    "    patience=5,          \n",
    "    restore_best_weights=True, \n",
    "    verbose=1            \n",
    ")\n",
    "\n",
    "# Measure the time\n",
    "start_training_time = time.time()\n",
    "\n",
    "# Fit the model with EarlyStopping\n",
    "history = model.fit(\n",
    "    trainX, trainX,\n",
    "    epochs=50,                  \n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    # callbacks=[early_stopping] \n",
    ")\n",
    "\n",
    "end_training_time = time.time()\n",
    "training_time = end_training_time - start_training_time\n",
    "print(f\"Total training time: {training_time:.2f} seconds\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17af4ed909f4d98c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# training history\n",
    "training_loss = history.history['loss']\n",
    "training_mape = history.history['rmse']\n",
    "val_loss = history.history['val_loss']\n",
    "val_mape = history.history['val_rmse']\n",
    "epochs = range(1, len(training_loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot training and validation loss \n",
    "plt.plot(epochs, training_loss, color='blue', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, color='green', label='Validation Loss')\n",
    "\n",
    "# # Plot training and validation MAPE \n",
    "# plt.plot(epochs, training_mape, color='orange', label='Training RMSE')\n",
    "# plt.plot(epochs, val_mape, color='red', label='Validation RMSE')\n",
    "\n",
    "plt.title('Training and Validation Loss / RMSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss / RMSE')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Extract the final loss and MAPE values\n",
    "final_training_loss = training_loss[-1]\n",
    "final_val_loss = val_loss[-1]\n",
    "final_training_mape = training_mape[-1]\n",
    "final_val_mape = val_mape[-1]\n",
    "\n",
    "# Print the final loss and MAPE values\n",
    "print(\"Final Training Loss:\", final_training_loss)\n",
    "print(\"Final Validation Loss:\", final_val_loss)\n",
    "print(\"Final Training RMSE:\", final_training_mape)\n",
    "print(\"Final Validation RMSE:\", final_val_mape)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ab3c667baa473a3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate MAE for training prediction\n",
    "trainPredict = model.predict(trainX)\n",
    "trainMAE = np.mean(np.abs(trainPredict - trainX), axis=1)\n",
    "# Print the mean of test MAE\n",
    "print(\"Mean of Train MAE:\", np.mean(trainMAE))\n",
    "\n",
    "print(trainMAE.shape)\n",
    "\n",
    "# Calculate MSE for training predictions\n",
    "trainMSE = np.mean(np.square(trainPredict - trainX), axis=1)\n",
    "\n",
    "# Calculate RMSE for training predictions\n",
    "trainRMSE = np.sqrt(trainMSE)\n",
    "\n",
    "# Print the mean of Train MSE and Train RMSE\n",
    "print(\"Mean of Train MSE:\", np.mean(trainMSE))\n",
    "print(\"Mean of Train RMSE:\", np.mean(trainRMSE))\n",
    "\n",
    "print(\"Shape of trainMSE:\", trainMSE.shape)\n",
    "print(\"Shape of trainRMSE:\", trainRMSE.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e32d490e75f64b9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# thresholding using MAPE \n",
    "trainMAE_Avg = average_threshold_train\n",
    "# Assuming testMAPE has multiple columns\n",
    "trainMAE_combined = np.mean(trainMAE, axis=1)  # Combine by averaging the columns\n",
    "\n",
    "# Create anomaly DataFrame\n",
    "anomaly_df = pd.DataFrame(train[seq_size:])\n",
    "anomaly_df['trainMAE'] = trainMAE_combined  # Use the combined MAPE\n",
    "anomaly_df['trainMAE_Avg'] = trainMAE_Avg  # Threshold\n",
    "anomaly_df['anomaly'] = anomaly_df['trainMAE'] > anomaly_df['trainMAE_Avg']\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=anomaly_df.index, y=anomaly_df['trainMAE'])\n",
    "sns.lineplot(x=anomaly_df.index, y=anomaly_df['trainMAE_Avg'])\n",
    "\n",
    "# Get y-axis limits to place the text within bounds\n",
    "y_min, y_max = plt.ylim()\n",
    "x_min, x_max = plt.xlim()\n",
    "\n",
    "# Add the threshold value as text in the top-right corner\n",
    "threshold_text = f\"Threshold: {average_threshold_train:.2f}\"\n",
    "plt.text(\n",
    "    x=x_max - (x_max - x_min) * 0.2,  # Slightly to the left of the right edge\n",
    "    y=y_max - (y_max - y_min) * 0.12,  # Slightly below the top edge\n",
    "    s=threshold_text,\n",
    "    color='red',\n",
    "    fontsize=10,\n",
    "    bbox=dict(facecolor='white', alpha=0.8)  # Add a background for better visibility\n",
    ")\n",
    "\n",
    "# Formatting\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.title(\"Training MAE vs Threshold (Combined Features)\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84399adc1a00f43"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data1 = pd.read_csv('Nano07V3_gt.csv')  \n",
    "\n",
    "# Select only the 'timestamp', 'jetson_gpu_usage_percent', 'jetson_cpu_usage_percent', and 'ground_truth' columns\n",
    "combined_data = data1[['timestamp', 'jetson_gpu_usage_percent', 'jetson_cpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_ram_usage_mb', 'ground_truth']]\n",
    "\n",
    "# Convert 'timestamp' to datetime format\n",
    "combined_data['timestamp'] = pd.to_datetime(combined_data['timestamp'])\n",
    "\n",
    "# Replace zero values with a small value (0.01) for all columns except 'ground_truth'\n",
    "columns_to_replace = combined_data.columns.difference(['ground_truth'])\n",
    "combined_data[columns_to_replace] = combined_data[columns_to_replace].replace(0, 0.01)\n",
    "\n",
    "# Verify the changes\n",
    "print(combined_data.head())\n",
    "\n",
    "# Filter rows where the timestamp's second is divisible by 5\n",
    "# combined_data = combined_data[combined_data['timestamp'].dt.second % 5 == 0]\n",
    "\n",
    "# Extract the columns to scale\n",
    "df_to_scale = combined_data[['jetson_gpu_usage_percent', 'jetson_cpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_ram_usage_mb']]\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler_standard = StandardScaler()\n",
    "\n",
    "# Perform scaling\n",
    "df_standard_scaled_1 = pd.DataFrame(scaler_standard.fit_transform(df_to_scale), \n",
    "                                  columns=df_to_scale.columns, \n",
    "                                  index=combined_data.index)\n",
    "\n",
    "# Add the 'timestamp' column back to the scaled data\n",
    "df_standard_scaled_1['timestamp'] = combined_data['timestamp']\n",
    "\n",
    "# Convert the combined dataset into sequences\n",
    "combined_X, combined_Y = to_sequence(df_standard_scaled_1[['jetson_gpu_usage_percent', 'jetson_cpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_ram_usage_mb']], df_standard_scaled_1[['jetson_gpu_usage_percent', 'jetson_cpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_ram_usage_mb']], seq_size)\n",
    "\n",
    "print(\"combined X shape\", combined_X.shape)\n",
    "print(\"combined Y shape\", combined_Y.shape)\n",
    "\n",
    "\n",
    "# Measure the time before starting the prediction\n",
    "start_time = time.time()\n",
    "\n",
    "# Use the trained model to predict the reconstruction errors (MAPE) on the combined dataset\n",
    "combined_predict = model.predict(combined_X)\n",
    "\n",
    "# Measure the time after prediction\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate total inference time\n",
    "inference_time = end_time - start_time\n",
    "print(f\"Total inference time: {inference_time:.2f} seconds\")\n",
    "\n",
    "# Calculate combined MAPE\n",
    "# combined_mape = np.mean(np.abs(combined_predict - combined_X) / combined_X, axis=1) * 100\n",
    "combined_mae = np.mean(np.abs(combined_predict - combined_X), axis=1)\n",
    "combined_mae_combined = np.mean(combined_mae, axis=1)\n",
    "\n",
    "combined_mse = np.mean(np.square(combined_predict - combined_X), axis=1)\n",
    "combined_mse_combined = np.mean(combined_mse, axis=1)\n",
    "\n",
    "combined_rmse = np.sqrt(combined_mse)\n",
    "combined_rmse_combined = np.mean(combined_rmse, axis=1)\n",
    "\n",
    "# Thresholding using MAPE\n",
    "# max_trainRMSE = average_threshold_train\n",
    "max_trainRMSE = threshold_99\n",
    "\n",
    "# Capture all details in a DataFrame for easy plotting\n",
    "anomaly_df = pd.DataFrame(df_standard_scaled_1[seq_size:])\n",
    "anomaly_df['combinedRMSE'] = combined_rmse_combined\n",
    "anomaly_df['max_trainRMSE'] = max_trainRMSE\n",
    "anomaly_df['anomaly'] = anomaly_df['combinedRMSE'] > max_trainRMSE\n",
    "anomaly_df[['jetson_gpu_usage_percent', 'jetson_cpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_ram_usage_mb']] = df_standard_scaled_1[seq_size:][['jetson_gpu_usage_percent', 'jetson_cpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_ram_usage_mb']]\n",
    "\n",
    "# Add the anomaly flag to the original test dataset\n",
    "combined_data['anomaly'] = False\n",
    "combined_data.loc[anomaly_df.index, 'anomaly'] = anomaly_df['anomaly'].values\n",
    "\n",
    "# Separate normal and anomalous data for plotting\n",
    "normal_data = combined_data[~combined_data['anomaly']]\n",
    "anomalous_data = combined_data[combined_data['anomaly']]\n",
    "\n",
    "# Plot combined RMSE with adjusted highlighted regions\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Highlight the area within the threshold in green\n",
    "plt.fill_between(anomaly_df.index, anomaly_df['max_trainRMSE'], anomaly_df['combinedRMSE'], \n",
    "                 where=anomaly_df['combinedRMSE'] <= anomaly_df['max_trainRMSE'], \n",
    "                 color='green', alpha=0.2, label='Normal Region')\n",
    "\n",
    "# Highlight the area above the threshold in red\n",
    "plt.fill_between(anomaly_df.index, anomaly_df['max_trainRMSE'], anomaly_df['combinedRMSE'], \n",
    "                 where=anomaly_df['combinedRMSE'] > anomaly_df['max_trainRMSE'], \n",
    "                 color='red', alpha=0.2, label='Anomalous Region')\n",
    "\n",
    "# Plot the RMSE values\n",
    "sns.lineplot(x=anomaly_df.index, y=anomaly_df['combinedRMSE'], label='Combined RMSE', color='blue', linewidth=2)\n",
    "\n",
    "# Plot the threshold line\n",
    "sns.lineplot(x=anomaly_df.index, y=anomaly_df['max_trainRMSE'], label='Threshold', color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "# Annotate the threshold value\n",
    "threshold_value = anomaly_df['max_trainRMSE'].iloc[0]  # Assuming the threshold is constant\n",
    "plt.text(x=anomaly_df.index[-1], \n",
    "         y=threshold_value, \n",
    "         s=f'Threshold: {threshold_value:.2f}', \n",
    "         color='red', \n",
    "         fontsize=12, \n",
    "         verticalalignment='bottom', \n",
    "         horizontalalignment='right', \n",
    "         bbox=dict(facecolor='white', edgecolor='red', boxstyle='round,pad=0.3'))\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Anomaly Detection on Testing Data (Version 3)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Index', fontsize=14)\n",
    "plt.ylabel('Root Mean Squared Error (RMSE)', fontsize=14)\n",
    "plt.xticks(fontsize=12, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add background color to make the plot more appealing\n",
    "plt.gcf().set_facecolor('white')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ca1300caa9458b5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data1 = pd.read_csv('Nano07V1_gt.csv')  \n",
    "\n",
    "# Select only the 'timestamp', 'jetson_gpu_usage_percent', 'jetson_cpu_usage_percent', and 'ground_truth' columns\n",
    "combined_data = data1[['timestamp', 'jetson_gpu_usage_percent', 'jetson_cpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_ram_usage_mb', 'ground_truth']]\n",
    "\n",
    "# Convert 'timestamp' to datetime format\n",
    "combined_data['timestamp'] = pd.to_datetime(combined_data['timestamp'])\n",
    "\n",
    "# Replace zero values with a small value (0.01) for all columns except 'ground_truth'\n",
    "columns_to_replace = combined_data.columns.difference(['ground_truth'])\n",
    "combined_data[columns_to_replace] = combined_data[columns_to_replace].replace(0, 0.01)\n",
    "\n",
    "# Verify the changes\n",
    "print(combined_data.head())\n",
    "\n",
    "# Filter rows where the timestamp's second is divisible by 5\n",
    "# combined_data = combined_data[combined_data['timestamp'].dt.second % 5 == 0]\n",
    "\n",
    "# Extract the columns to scale\n",
    "df_to_scale = combined_data[['jetson_gpu_usage_percent', 'jetson_cpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_ram_usage_mb']]\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler_standard = StandardScaler()\n",
    "\n",
    "# Perform scaling\n",
    "df_standard_scaled_1 = pd.DataFrame(scaler_standard.fit_transform(df_to_scale), \n",
    "                                  columns=df_to_scale.columns, \n",
    "                                  index=combined_data.index)\n",
    "\n",
    "# Add the 'timestamp' column back to the scaled data\n",
    "df_standard_scaled_1['timestamp'] = combined_data['timestamp']\n",
    "\n",
    "# Plot the scaled data\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='timestamp', y='jetson_gpu_usage_percent', data=df_standard_scaled_1, label='GPU Usage (Standard)')\n",
    "sns.lineplot(x='timestamp', y='jetson_cpu_usage_percent', data=df_standard_scaled_1, label='CPU Usage (Standard)')\n",
    "sns.lineplot(x='timestamp', y='jetson_board_temperature_celsius', data=df_standard_scaled_1, label='Board Temperature (Standard)')\n",
    "sns.lineplot(x='timestamp', y='jetson_ram_usage_mb', data=df_standard_scaled_1, label='RAM Usage (Standard)')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Scaled Jetson Device Metrics Over Time (Standard Scaler)')\n",
    "plt.ylabel('Standardized Values')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.xticks(rotation=45)\n",
    "plt.gcf().set_facecolor('white')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Convert the combined dataset into sequences\n",
    "combined_X, combined_Y = to_sequence(df_standard_scaled_1[['jetson_gpu_usage_percent', 'jetson_cpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_ram_usage_mb']], df_standard_scaled_1[['jetson_gpu_usage_percent', 'jetson_cpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_ram_usage_mb']], seq_size)\n",
    "\n",
    "print(\"combined X shape\", combined_X.shape)\n",
    "print(\"combined Y shape\", combined_Y.shape)\n",
    "\n",
    "\n",
    "# Measure the time before starting the prediction\n",
    "start_time = time.time()\n",
    "\n",
    "# Use the trained model to predict the reconstruction errors (MAPE) on the combined dataset\n",
    "combined_predict = model.predict(combined_X)\n",
    "\n",
    "# Measure the time after prediction\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate total inference time\n",
    "inference_time = end_time - start_time\n",
    "print(f\"Total inference time: {inference_time:.2f} seconds\")\n",
    "\n",
    "# Calculate combined MAPE\n",
    "# combined_mape = np.mean(np.abs(combined_predict - combined_X) / combined_X, axis=1) * 100\n",
    "combined_mae = np.mean(np.abs(combined_predict - combined_X), axis=1)\n",
    "combined_mae_combined = np.mean(combined_mae, axis=1)\n",
    "\n",
    "combined_mse = np.mean(np.square(combined_predict - combined_X), axis=1)\n",
    "combined_mse_combined = np.mean(combined_mse, axis=1)\n",
    "\n",
    "combined_rmse = np.sqrt(combined_mse)\n",
    "combined_rmse_combined = np.mean(combined_rmse, axis=1)\n",
    "\n",
    "# Thresholding using MAPE\n",
    "# max_trainRMSE = average_threshold_train\n",
    "max_trainRMSE = threshold_99\n",
    "\n",
    "# Capture all details in a DataFrame for easy plotting\n",
    "anomaly_df = pd.DataFrame(df_standard_scaled_1[seq_size:])\n",
    "anomaly_df['combinedRMSE'] = combined_rmse_combined\n",
    "anomaly_df['max_trainRMSE'] = max_trainRMSE\n",
    "anomaly_df['anomaly'] = anomaly_df['combinedRMSE'] > max_trainRMSE\n",
    "anomaly_df[['jetson_gpu_usage_percent', 'jetson_cpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_ram_usage_mb']] = df_standard_scaled_1[seq_size:][['jetson_gpu_usage_percent', 'jetson_cpu_usage_percent', 'jetson_board_temperature_celsius', 'jetson_ram_usage_mb']]\n",
    "\n",
    "# Plot combined MAE vs max_trainMAE\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=anomaly_df.index, y=anomaly_df['combinedRMSE'], label='RMSE')\n",
    "sns.lineplot(x=anomaly_df.index, y=anomaly_df['max_trainRMSE'], label='Threshold', linestyle='--', color='red')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Root Mean Sq Error (RMSE)')\n",
    "plt.title('Anomaly Detection on Testing Dataset')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Add the anomaly flag to the original test dataset\n",
    "combined_data['anomaly'] = False\n",
    "combined_data.loc[anomaly_df.index, 'anomaly'] = anomaly_df['anomaly'].values\n",
    "\n",
    "# Separate normal and anomalous data for plotting\n",
    "normal_data = combined_data[~combined_data['anomaly']]\n",
    "anomalous_data = combined_data[combined_data['anomaly']]\n",
    "\n",
    "# # Plot the original metrics with anomalies highlighted\n",
    "# plt.figure(figsize=(14, 8))\n",
    "\n",
    "# # Plot normal data\n",
    "# sns.lineplot(x='timestamp', y='jetson_gpu_usage_percent', data=normal_data, label='GPU Usage (Normal)', color='blue')\n",
    "# sns.lineplot(x='timestamp', y='jetson_cpu_usage_percent', data=normal_data, label='CPU Usage (Normal)', color='green')\n",
    "# sns.lineplot(x='timestamp', y='jetson_board_temperature_celsius', data=normal_data, label='Board Temperature (Normal)', color='green')\n",
    "# sns.lineplot(x='timestamp', y='jetson_ram_usage_mb', data=normal_data, label='RAM Usage (Standard)')\n",
    "\n",
    "\n",
    "# # Overlay anomalous points\n",
    "# plt.scatter(anomalous_data['timestamp'], anomalous_data['jetson_gpu_usage_percent'], \n",
    "#             color='red', label='GPU Usage (Anomalous)', s=40, zorder=3)\n",
    "# plt.scatter(anomalous_data['timestamp'], anomalous_data['jetson_cpu_usage_percent'], \n",
    "#             color='orange', label='CPU Usage (Anomalous)', s=40, zorder=3)\n",
    "# plt.scatter(anomalous_data['timestamp'], anomalous_data['jetson_board_temperature_celsius'], \n",
    "#             color='yellow', label='Board Temperature (Anomalous)', s=40, zorder=3)\n",
    "# plt.scatter(anomalous_data['timestamp'], anomalous_data['jetson_ram_usage_mb'], \n",
    "#             color='yellow', label='RAM Usage (Anomalous)', s=40, zorder=3)\n",
    "\n",
    "# # Customize the plot\n",
    "# plt.title('Jetson Device Metrics with Anomalies Highlighted')\n",
    "# plt.xlabel('Timestamp')\n",
    "# plt.ylabel('Usage (%)')\n",
    "# plt.legend()\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.gcf().set_facecolor('white')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Plot combined RMSE with adjusted highlighted regions\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Highlight the area within the threshold in green\n",
    "plt.fill_between(anomaly_df.index, anomaly_df['max_trainRMSE'], anomaly_df['combinedRMSE'], \n",
    "                 where=anomaly_df['combinedRMSE'] <= anomaly_df['max_trainRMSE'], \n",
    "                 color='green', alpha=0.2, label='Normal Region')\n",
    "\n",
    "# Highlight the area above the threshold in red\n",
    "plt.fill_between(anomaly_df.index, anomaly_df['max_trainRMSE'], anomaly_df['combinedRMSE'], \n",
    "                 where=anomaly_df['combinedRMSE'] > anomaly_df['max_trainRMSE'], \n",
    "                 color='red', alpha=0.2, label='Anomalous Region')\n",
    "\n",
    "# Plot the RMSE values\n",
    "sns.lineplot(x=anomaly_df.index, y=anomaly_df['combinedRMSE'], label='Combined RMSE', color='blue', linewidth=2)\n",
    "\n",
    "# Plot the threshold line\n",
    "sns.lineplot(x=anomaly_df.index, y=anomaly_df['max_trainRMSE'], label='Threshold', color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Anomaly Detection on Jetson Device Metrics', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Index', fontsize=14)\n",
    "plt.ylabel('Root Mean Squared Error (RMSE)', fontsize=14)\n",
    "plt.xticks(fontsize=12, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add background color to make the plot more appealing\n",
    "plt.gcf().set_facecolor('white')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bdc131a73226ee9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Assuming 'anomaly' is the predicted anomalies (from your model)\n",
    "# and 'ground_truth' is the true anomaly labels from the dataset.\n",
    "\n",
    "# Compare ground truth with predicted anomalies (model's 'anomaly' column)\n",
    "y_true = combined_data['ground_truth']  # Actual labels (0 or 1)\n",
    "y_pred = combined_data['anomaly'].astype(int)  # Predicted anomalies (0 or 1)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n",
    "\n",
    "# Precision, Recall, F1-Score, and Accuracy\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cabd971f41eba59"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### Plot actual vs predicted values ###\n",
    "\n",
    "\n",
    "def plot_predictions(data, predictions, columns, dataset_name, seq_size):\n",
    "    \"\"\"Plot actual vs predicted values\"\"\"\n",
    "    fig, axes = plt.subplots(len(columns), 1, figsize=(15, 5*len(columns)))\n",
    "    if len(columns) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (ax, col) in enumerate(zip(axes, columns)):\n",
    "        # Plot actual values\n",
    "        ax.plot(data['datetimestamp'][seq_size:], data[col][seq_size:], \n",
    "                label='Actual', color='blue', alpha=0.6)\n",
    "        \n",
    "        # Plot predicted values\n",
    "        ax.plot(data['datetimestamp'][seq_size:], predictions[:, i], \n",
    "                label='Predicted', color='green', alpha=0.6)\n",
    "        \n",
    "        ax.set_title(f'{dataset_name}: {col} - Actual vs Predicted')\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Value')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f'{dataset_name}_predictions.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def analyze_dataset(data_path: str, dataset_name: str, model):\n",
    "    \"\"\"Analyze dataset and generate predictions visualization\"\"\"\n",
    "    # Load and preprocess data\n",
    "    data = pd.read_csv(data_path)\n",
    "    data['datetimestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    \n",
    "    columns = [\n",
    "        'jetson_gpu_usage_percent',\n",
    "        'jetson_board_temperature_celsius',\n",
    "        'jetson_cpu_usage_percent',\n",
    "        'jetson_ram_usage_mb'\n",
    "    ]\n",
    "    \n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data[columns])\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=columns)\n",
    "    \n",
    "    # Initialize variables\n",
    "    seq_size = 20\n",
    "    predictions = np.zeros((len(data) - seq_size, len(columns)))\n",
    "    \n",
    "    # Generate predictions using sliding window\n",
    "    for i in range(len(data) - seq_size):\n",
    "        sequence = scaled_df.iloc[i:i+seq_size].values.reshape(1, seq_size, len(columns))\n",
    "        pred = model.predict(sequence, verbose=0)\n",
    "        #predictions[i] = pred[0][10]  # Use the mid timestep prediction\n",
    "        #predictions[i] = pred[0][-1]  # Use the last timestep prediction\n",
    "        predictions[i] = pred[0][0]  # Use the first timestep prediction\n",
    "    \n",
    "    # Inverse transform predictions for plotting\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    # Generate visualization\n",
    "    plot_predictions(data, predictions, columns, dataset_name, seq_size)\n",
    "    \n",
    "    # Analyze dataset\n",
    "analyze_dataset('Nano07V1_gt.csv', 'V1_gt', model)\n",
    "#analyze_dataset('Nano07V2_gt.csv', 'V2_gt', model)\n",
    "analyze_dataset('Nano07V3_gt.csv', 'V3_gt', model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1f866a9499426d0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset saved to Nano07V1_gt.csv\n"
     ]
    }
   ],
   "source": [
    "# labeling test dataset \n",
    "\n",
    "file_path = \"C:/Users/muhammad.karim/Downloads/Nano07-V1.csv\"  # Update with the path to your file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the timestamp column is in datetime format\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Define the time range for ground truth\n",
    "start_time = pd.Timestamp(\"18:03:00\").time()\n",
    "end_time = pd.Timestamp(\"18:18:00\").time()\n",
    "\n",
    "# Add the ground_truth column\n",
    "df['ground_truth'] = df['timestamp'].apply(lambda x: 1 if start_time <= x.time() <= end_time else 0)\n",
    "\n",
    "# Save the updated dataset to a new CSV file\n",
    "output_path = \"Nano07V1_gt.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Updated dataset saved to {output_path}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T18:32:00.618624300Z",
     "start_time": "2025-01-17T18:32:00.545655600Z"
    }
   },
   "id": "623ff8f9fd22e606",
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
